{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from regression import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train_80= pd.read_csv(\"../data/train80.csv\")\n",
    "train_70= pd.read_csv(\"../data/train70.csv\")\n",
    "test_20= pd.read_csv(\"../data/test20.csv\")\n",
    "test_30= pd.read_csv(\"../data/test30.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Linear Regression with split ratio 0.2 ---\n",
      "\n",
      "Training on 1166912 samples, testing on 291728 samples.\n",
      "Linear Regression Training RMSE (log): 0.6387\n",
      "Linear Regression Test RMSE (log): 0.6437\n",
      "\n",
      "--- Training Linear Regression with split ratio 0.3 ---\n",
      "\n",
      "Training on 1021048 samples, testing on 437592 samples.\n",
      "Linear Regression Training RMSE (log): 0.6422\n",
      "Linear Regression Test RMSE (log): 0.6345\n",
      "\n",
      "--- Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [ 'haversine_distance',\n",
    "                'manhattan_distance',\n",
    "                'pickup_hour_sin',\n",
    "                'pickup_hour_cos', \n",
    "                'pickup_weekday_sin', \n",
    "                'pickup_weekday_cos', \n",
    "                'pickup_minute_sin', \n",
    "                'pickup_minute_cos', \n",
    "                'weekend_indicator', \n",
    "                'rush_hour', \n",
    "                'store_and_fwd_flag', \n",
    "                'direction_NS', \n",
    "                'direction_EW', \n",
    "                'vendor_id', \n",
    "                'passenger_count' ]\n",
    "\n",
    "X1_train = train_80[feature_cols]\n",
    "y1_train = train_80['log_trip_duration']\n",
    "X1_test= test_20[feature_cols]\n",
    "y1_test= test_20['log_trip_duration']\n",
    "\n",
    "X2_train = train_70[feature_cols]\n",
    "y2_train = train_70['log_trip_duration']\n",
    "X2_test= test_30[feature_cols]\n",
    "y2_test= test_30['log_trip_duration']\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_regression', MyLinearRegression())\n",
    "])\n",
    "\n",
    "print(\"--- Training Linear Regression with split ratio 0.2 ---\\n\")\n",
    "print(f\"Training on {len(X1_train)} samples, testing on {len(X1_test)} samples.\")\n",
    "lr_pipeline.fit(X1_train, y1_train)\n",
    "y1_train_pred_lr = lr_pipeline.predict(X1_train)\n",
    "y1_test_pred_lr = lr_pipeline.predict(X1_test)\n",
    "rmse_train_X1_lr = np.sqrt(mse(y1_train, y1_train_pred_lr))\n",
    "rmse_test_X1_lr = np.sqrt(mse(y1_test, y1_test_pred_lr))\n",
    "print(f\"Linear Regression Training RMSE (log): {rmse_train_X1_lr:.4f}\")\n",
    "print(f\"Linear Regression Test RMSE (log): {rmse_test_X1_lr:.4f}\\n\")\n",
    "\n",
    "print(\"--- Training Linear Regression with split ratio 0.3 ---\\n\")\n",
    "print(f\"Training on {len(X2_train)} samples, testing on {len(X2_test)} samples.\")\n",
    "lr_pipeline.fit(X2_train, y2_train)\n",
    "y2_train_pred_lr = lr_pipeline.predict(X2_train)\n",
    "y2_test_pred_lr = lr_pipeline.predict(X2_test)\n",
    "rmse_train_X2_lr = np.sqrt(mse(y2_train, y2_train_pred_lr))\n",
    "rmse_test_X2_lr = np.sqrt(mse(y2_test, y2_test_pred_lr))\n",
    "print(f\"Linear Regression Training RMSE (log): {rmse_train_X2_lr:.4f}\")\n",
    "print(f\"Linear Regression Test RMSE (log): {rmse_test_X2_lr:.4f}\\n\")\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Polynomial Regression (Degree 2) for split ratio 0.2 ---\n",
      "\n",
      "Polynomial Regression Training RMSE (log): 0.5940\n",
      "Polynomial Regression Test RMSE (log): 0.5986\n",
      "\n",
      "--- Training Polynomial Regression (Degree 2) for split ratio 0.3 ---\n",
      "\n",
      "Polynomial Regression Training RMSE (log): 0.5939\n",
      "Polynomial Regression Test RMSE (log): 0.5973\n",
      "\n",
      "--- Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [ 'haversine_distance',\n",
    "                'manhattan_distance',\n",
    "                'pickup_hour_sin',\n",
    "                'pickup_hour_cos', \n",
    "                'pickup_weekday_sin', \n",
    "                'pickup_weekday_cos', \n",
    "                'pickup_minute_sin', \n",
    "                'pickup_minute_cos', \n",
    "                'weekend_indicator', \n",
    "                'rush_hour', \n",
    "                'store_and_fwd_flag', \n",
    "                'direction_NS', \n",
    "                'direction_EW', \n",
    "                'vendor_id', \n",
    "                'passenger_count' ]\n",
    "\n",
    "degree = 2\n",
    "\n",
    "X1_train = train_80[feature_cols].values\n",
    "y1_train = train_80['log_trip_duration']\n",
    "X1_test= test_20[feature_cols].values\n",
    "y1_test= test_20['log_trip_duration']\n",
    "\n",
    "X2_train = train_70[feature_cols].values\n",
    "y2_train = train_70['log_trip_duration']\n",
    "X2_test= test_30[feature_cols].values\n",
    "y2_test= test_30['log_trip_duration']\n",
    "\n",
    "X1_train_poly = create_polynomial_features(X1_train, degree)\n",
    "X1_test_poly = create_polynomial_features(X1_test, degree)\n",
    "X2_train_poly = create_polynomial_features(X2_train, degree)\n",
    "X2_test_poly = create_polynomial_features(X2_test, degree)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "poly_model = MyLinearRegression()\n",
    "\n",
    "X1_train_scaled = scaler.fit_transform(X1_train_poly)\n",
    "X1_test_scaled = scaler.transform(X1_test_poly)\n",
    "X2_train_scaled = scaler.fit_transform(X2_train_poly)\n",
    "X2_test_scaled = scaler.transform(X2_test_poly)\n",
    "\n",
    "poly_model.fit(X1_train_scaled, y1_train)\n",
    "poly_model.fit(X2_train_scaled, y2_train)\n",
    "\n",
    "y1_train_pred_poly = poly_model.predict(X1_train_scaled)\n",
    "y1_test_pred_poly = poly_model.predict(X1_test_scaled)\n",
    "y2_train_pred_poly = poly_model.predict(X2_train_scaled)\n",
    "y2_test_pred_poly = poly_model.predict(X2_test_scaled)\n",
    "   \n",
    "rmse_train_X1_poly = np.sqrt(mse(y1_train, y1_train_pred_poly))\n",
    "rmse_test_X1_poly = np.sqrt(mse(y1_test, y1_test_pred_poly))\n",
    "rmse_train_X2_poly = np.sqrt(mse(y2_train, y2_train_pred_poly))\n",
    "rmse_test_X2_poly = np.sqrt(mse(y2_test, y2_test_pred_poly))\n",
    "\n",
    "print(f\"--- Training Polynomial Regression (Degree {degree}) for split ratio 0.2 ---\\n\")\n",
    "print(f\"Polynomial Regression Training RMSE (log): {rmse_train_X1_poly:.4f}\")\n",
    "print(f\"Polynomial Regression Test RMSE (log): {rmse_test_X1_poly:.4f}\\n\")\n",
    "\n",
    "print(f\"--- Training Polynomial Regression (Degree {degree}) for split ratio 0.3 ---\\n\")\n",
    "print(f\"Polynomial Regression Training RMSE (log): {rmse_train_X2_poly:.4f}\")\n",
    "print(f\"Polynomial Regression Test RMSE (log): {rmse_test_X2_poly:.4f}\\n\")\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Ridge Regression Evaluation (alpha=10.0)  for split ratio 0.2---\n",
      "\n",
      "  [Linear Features] Ridge Training RMSE (log): 0.6388\n",
      "  [Linear Features] Ridge Test RMSE (log): 0.6442\n",
      "  [Polynomial Features] Ridge Training RMSE (log): 0.5945\n",
      "  [Polynomial Features] Ridge Test RMSE (log): 0.6010\n",
      "\n",
      "--- Starting Ridge Regression Evaluation (alpha=10.0)  for split ratio 0.3---\n",
      "\n",
      "  [Linear Features] Ridge Training RMSE (log): 0.6422\n",
      "  [Linear Features] Ridge Test RMSE (log): 0.6345\n",
      "  [Polynomial Features] Ridge Training RMSE (log): 0.5945\n",
      "  [Polynomial Features] Ridge Test RMSE (log): 0.5990\n",
      "\n",
      "--- Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [ 'haversine_distance',\n",
    "                'manhattan_distance',\n",
    "                'pickup_hour_sin',\n",
    "                'pickup_hour_cos', \n",
    "                'pickup_weekday_sin', \n",
    "                'pickup_weekday_cos', \n",
    "                'pickup_minute_sin', \n",
    "                'pickup_minute_cos', \n",
    "                'weekend_indicator', \n",
    "                'rush_hour', \n",
    "                'store_and_fwd_flag', \n",
    "                'direction_NS', \n",
    "                'direction_EW', \n",
    "                'vendor_id', \n",
    "                'passenger_count' ]\n",
    "\n",
    "degree = 2\n",
    "alpha_value = 1.0\n",
    "\n",
    "X1_train = train_80[feature_cols].values\n",
    "y1_train = train_80['log_trip_duration']\n",
    "X1_test= test_20[feature_cols].values\n",
    "y1_test= test_20['log_trip_duration']\n",
    "\n",
    "X2_train = train_70[feature_cols].values\n",
    "y2_train = train_70['log_trip_duration']\n",
    "X2_test= test_30[feature_cols].values\n",
    "y2_test= test_30['log_trip_duration']\n",
    "\n",
    "scaler_linear = StandardScaler()\n",
    "scaler_poly = StandardScaler()\n",
    "ridge_linear_model = MyRidgeRegression(alpha=alpha_value)\n",
    "ridge_poly_model = MyRidgeRegression(alpha=alpha_value)\n",
    "\n",
    "X1_train_scaled_linear = scaler_linear.fit_transform(X1_train)\n",
    "X1_test_scaled_linear = scaler_linear.transform(X1_test)\n",
    "X2_train_scaled_linear = scaler_linear.fit_transform(X2_train)\n",
    "X2_test_scaled_linear = scaler_linear.transform(X2_test)\n",
    "\n",
    "ridge_linear_model.fit(X1_train_scaled_linear, y1_train)\n",
    "ridge_linear_model.fit(X2_train_scaled_linear, y2_train)\n",
    "\n",
    "y1_train_pred_linear = ridge_linear_model.predict(X1_train_scaled_linear)\n",
    "y1_test_pred_linear = ridge_linear_model.predict(X1_test_scaled_linear)\n",
    "y2_train_pred_linear = ridge_linear_model.predict(X2_train_scaled_linear)\n",
    "y2_test_pred_linear = ridge_linear_model.predict(X2_test_scaled_linear)\n",
    "\n",
    "rmse_train_y1_linear = np.sqrt(mse(y1_train, y1_train_pred_linear))\n",
    "rmse_test_y1_linear = np.sqrt(mse(y1_test, y1_test_pred_linear))\n",
    "rmse_train_y2_linear = np.sqrt(mse(y2_train, y2_train_pred_linear))\n",
    "rmse_test_y2_linear = np.sqrt(mse(y2_test, y2_test_pred_linear))\n",
    "\n",
    "X1_train_poly = create_polynomial_features(X1_train, degree)\n",
    "X1_test_poly = create_polynomial_features(X1_test, degree)\n",
    "X2_train_poly = create_polynomial_features(X2_train, degree)\n",
    "X2_test_poly = create_polynomial_features(X2_test, degree)\n",
    "\n",
    "X1_train_scaled_poly = scaler_poly.fit_transform(X1_train_poly)\n",
    "X1_test_scaled_poly = scaler_poly.transform(X1_test_poly)\n",
    "X2_train_scaled_poly = scaler_poly.fit_transform(X2_train_poly)\n",
    "X2_test_scaled_poly = scaler_poly.transform(X2_test_poly)\n",
    "\n",
    "ridge_poly_model.fit(X1_train_scaled_poly, y1_train)\n",
    "ridge_poly_model.fit(X2_train_scaled_poly, y2_train)\n",
    "\n",
    "y1_train_pred_poly = ridge_poly_model.predict(X1_train_scaled_poly)\n",
    "y1_test_pred_poly = ridge_poly_model.predict(X1_test_scaled_poly)\n",
    "y2_train_pred_poly = ridge_poly_model.predict(X2_train_scaled_poly)\n",
    "y2_test_pred_poly = ridge_poly_model.predict(X2_test_scaled_poly)\n",
    "\n",
    "rmse_train_y1_poly = np.sqrt(mse(y1_train, y1_train_pred_poly))\n",
    "rmse_test_y1_poly = np.sqrt(mse(y1_test, y1_test_pred_poly))\n",
    "rmse_train_y2_poly = np.sqrt(mse(y2_train, y2_train_pred_poly))\n",
    "rmse_test_y2_poly = np.sqrt(mse(y2_test, y2_test_pred_poly))\n",
    "\n",
    "print(f\"--- Starting Ridge Regression Evaluation (alpha={alpha_value})  for split ratio 0.2---\\n\")\n",
    "print(f\"  [Linear Features] Ridge Training RMSE (log): {rmse_train_y1_linear:.4f}\")\n",
    "print(f\"  [Linear Features] Ridge Test RMSE (log): {rmse_test_y1_linear:.4f}\")\n",
    "print(f\"  [Polynomial Features] Ridge Training RMSE (log): {rmse_train_y1_poly:.4f}\")\n",
    "print(f\"  [Polynomial Features] Ridge Test RMSE (log): {rmse_test_y1_poly:.4f}\\n\")\n",
    "\n",
    "print(f\"--- Starting Ridge Regression Evaluation (alpha={alpha_value})  for split ratio 0.3---\\n\")\n",
    "print(f\"  [Linear Features] Ridge Training RMSE (log): {rmse_train_y2_linear:.4f}\")\n",
    "print(f\"  [Linear Features] Ridge Test RMSE (log): {rmse_test_y2_linear:.4f}\")\n",
    "print(f\"  [Polynomial Features] Ridge Training RMSE (log): {rmse_train_y2_poly:.4f}\")\n",
    "print(f\"  [Polynomial Features] Ridge Test RMSE (log): {rmse_test_y2_poly:.4f}\\n\")\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Lasso Regression Evaluation (alpha=0.01)  for split ratio 0.2---\n",
      "\n",
      "  [Linear Features] Lasso Training RMSE (log): 0.6388\n",
      "  [Linear Features] Lasso Test RMSE (log): 0.6442\n",
      "  [Polynomial Features] Lasso Training RMSE (log): 0.5948\n",
      "  [Polynomial Features] Lasso Test RMSE (log): 0.6014\n",
      "\n",
      "--- Starting Lasso Regression Evaluation (alpha=0.01)  for split ratio 0.3---\n",
      "\n",
      "  [Linear Features] Lasso Training RMSE (log): 0.6422\n",
      "  [Linear Features] Lasso Test RMSE (log): 0.6345\n",
      "  [Polynomial Features] Lasso Training RMSE (log): 0.5948\n",
      "  [Polynomial Features] Lasso Test RMSE (log): 0.5993\n",
      "\n",
      "--- Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [ 'haversine_distance',\n",
    "                'manhattan_distance',\n",
    "                'pickup_hour_sin',\n",
    "                'pickup_hour_cos', \n",
    "                'pickup_weekday_sin', \n",
    "                'pickup_weekday_cos', \n",
    "                'pickup_minute_sin', \n",
    "                'pickup_minute_cos', \n",
    "                'weekend_indicator', \n",
    "                'rush_hour', \n",
    "                'store_and_fwd_flag', \n",
    "                'direction_NS', \n",
    "                'direction_EW', \n",
    "                'vendor_id', \n",
    "                'passenger_count' ]\n",
    "\n",
    "degree = 2\n",
    "alpha_value = 0.01\n",
    "n_iters = 1000\n",
    "\n",
    "X1_train = train_80[feature_cols].values\n",
    "y1_train = train_80['log_trip_duration']\n",
    "X1_test= test_20[feature_cols].values\n",
    "y1_test= test_20['log_trip_duration']\n",
    "\n",
    "X2_train = train_70[feature_cols].values\n",
    "y2_train = train_70['log_trip_duration']\n",
    "X2_test= test_30[feature_cols].values\n",
    "y2_test= test_30['log_trip_duration']\n",
    "\n",
    "scaler_linear = StandardScaler()\n",
    "scaler_poly = StandardScaler()\n",
    "lasso_linear_model = MyLassoRegression(alpha=alpha_value, n_iterations=n_iters)\n",
    "lasso_poly_model = MyLassoRegression(alpha=alpha_value, n_iterations=n_iters)\n",
    "\n",
    "X1_train_scaled_linear = scaler_linear.fit_transform(X1_train)\n",
    "X1_test_scaled_linear = scaler_linear.transform(X1_test)\n",
    "X2_train_scaled_linear = scaler_linear.fit_transform(X2_train)\n",
    "X2_test_scaled_linear = scaler_linear.transform(X2_test)\n",
    "\n",
    "lasso_linear_model.fit(X1_train_scaled_linear, y1_train)\n",
    "lasso_linear_model.fit(X2_train_scaled_linear, y2_train)\n",
    "\n",
    "y1_train_pred_linear = lasso_linear_model.predict(X1_train_scaled_linear)\n",
    "y1_test_pred_linear = lasso_linear_model.predict(X1_test_scaled_linear)\n",
    "y2_train_pred_linear = lasso_linear_model.predict(X2_train_scaled_linear)\n",
    "y2_test_pred_linear = lasso_linear_model.predict(X2_test_scaled_linear)\n",
    "\n",
    "rmse_train_y1_linear = np.sqrt(mse(y1_train, y1_train_pred_linear))\n",
    "rmse_test_y1_linear = np.sqrt(mse(y1_test, y1_test_pred_linear))\n",
    "rmse_train_y2_linear = np.sqrt(mse(y2_train, y2_train_pred_linear))\n",
    "rmse_test_y2_linear = np.sqrt(mse(y2_test, y2_test_pred_linear))\n",
    "\n",
    "X1_train_poly = create_polynomial_features(X1_train, degree)\n",
    "X1_test_poly = create_polynomial_features(X1_test, degree)\n",
    "X2_train_poly = create_polynomial_features(X2_train, degree)\n",
    "X2_test_poly = create_polynomial_features(X2_test, degree)\n",
    "\n",
    "X1_train_scaled_poly = scaler_poly.fit_transform(X1_train_poly)\n",
    "X1_test_scaled_poly = scaler_poly.transform(X1_test_poly)\n",
    "X2_train_scaled_poly = scaler_poly.fit_transform(X2_train_poly)\n",
    "X2_test_scaled_poly = scaler_poly.transform(X2_test_poly)\n",
    "\n",
    "lasso_poly_model.fit(X1_train_scaled_poly, y1_train)\n",
    "lasso_poly_model.fit(X2_train_scaled_poly, y2_train)\n",
    "\n",
    "y1_train_pred_poly = lasso_poly_model.predict(X1_train_scaled_poly)\n",
    "y1_test_pred_poly = lasso_poly_model.predict(X1_test_scaled_poly)\n",
    "y2_train_pred_poly = lasso_poly_model.predict(X2_train_scaled_poly)\n",
    "y2_test_pred_poly = lasso_poly_model.predict(X2_test_scaled_poly)\n",
    "\n",
    "rmse_train_y1_poly = np.sqrt(mse(y1_train, y1_train_pred_poly))\n",
    "rmse_test_y1_poly = np.sqrt(mse(y1_test, y1_test_pred_poly))\n",
    "rmse_train_y2_poly = np.sqrt(mse(y2_train, y2_train_pred_poly))\n",
    "rmse_test_y2_poly = np.sqrt(mse(y2_test, y2_test_pred_poly))\n",
    "\n",
    "print(f\"--- Starting Lasso Regression Evaluation (alpha={alpha_value})  for split ratio 0.2---\\n\")\n",
    "print(f\"  [Linear Features] Lasso Training RMSE (log): {rmse_train_y1_linear:.4f}\")\n",
    "print(f\"  [Linear Features] Lasso Test RMSE (log): {rmse_test_y1_linear:.4f}\")\n",
    "print(f\"  [Polynomial Features] Lasso Training RMSE (log): {rmse_train_y1_poly:.4f}\")\n",
    "print(f\"  [Polynomial Features] Lasso Test RMSE (log): {rmse_test_y1_poly:.4f}\\n\")\n",
    "\n",
    "print(f\"--- Starting Lasso Regression Evaluation (alpha={alpha_value})  for split ratio 0.3---\\n\")\n",
    "print(f\"  [Linear Features] Lasso Training RMSE (log): {rmse_train_y2_linear:.4f}\")\n",
    "print(f\"  [Linear Features] Lasso Test RMSE (log): {rmse_test_y2_linear:.4f}\")\n",
    "print(f\"  [Polynomial Features] Lasso Training RMSE (log): {rmse_train_y2_poly:.4f}\")\n",
    "print(f\"  [Polynomial Features] Lasso Test RMSE (log): {rmse_test_y2_poly:.4f}\\n\")\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV on Ridge Regression (alpha range: [0.001 0.01  0.1   1.   ]) with 1166912 samples...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] END ........................................alpha=0.001; total time=   1.1s\n",
      "[CV] END ........................................alpha=0.001; total time=   1.1s\n",
      "[CV] END .........................................alpha=0.01; total time=   1.1s\n",
      "[CV] END ........................................alpha=0.001; total time=   1.1s\n",
      "[CV] END .........................................alpha=0.01; total time=   1.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   1.1s\n",
      "[CV] END ..........................................alpha=0.1; total time=   1.1s\n",
      "[CV] END .........................................alpha=0.01; total time=   1.2s\n",
      "[CV] END ..........................................alpha=0.1; total time=   1.1s\n",
      "[CV] END ..........................................alpha=1.0; total time=   1.0s\n",
      "[CV] END ..........................................alpha=1.0; total time=   1.1s\n",
      "[CV] END ..........................................alpha=1.0; total time=   1.0s\n",
      "\n",
      "--- GridSearchCV Results ---\n",
      "Tuning Time: 4.12s\n",
      "Best Alpha found: 1.0\n",
      "Best Cross-Validation Training RMSE (log): 1.1167\n",
      "Final Test RMSE (log) with best model: 0.6113\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train_to_tune = X1_train_scaled_poly\n",
    "y_train_to_tune = y1_train\n",
    "y_train_values = y_train_to_tune.values\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-3, 0, 4) # Search alphas: 0.001, 0.01, 0.1, 1\n",
    "}\n",
    "\n",
    "ridge_model = Ridge(random_state=42)\n",
    "print(f\"Starting GridSearchCV on Ridge Regression (alpha range: {param_grid['alpha']}) with {len(X_train_to_tune)} samples...\")\n",
    "start_time_grid = time.time()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_to_tune, y_train_values)\n",
    "end_time_grid = time.time()\n",
    "tuning_time = end_time_grid - start_time_grid\n",
    "\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_rmse = np.sqrt(abs(grid_search.best_score_))\n",
    "test_pred = grid_search.predict(X1_test_scaled_poly)\n",
    "test_rmse = np.sqrt(mse(y1_test, test_pred))\n",
    "\n",
    "print(f\"\\n--- GridSearchCV Results ---\")\n",
    "print(f\"Tuning Time: {tuning_time:.2f}s\")\n",
    "print(f\"Best Alpha found: {best_alpha}\")\n",
    "print(f\"Best Cross-Validation Training RMSE (log): {best_rmse:.4f}\")\n",
    "print(f\"Final Test RMSE (log) with best model: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV on Lasso Regression (alpha range: [0.001 0.01  0.1   1.   ]) with 1166912 samples...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] END .........................................alpha=0.01; total time=  19.4s\n",
      "[CV] END .........................................alpha=0.01; total time=   8.7s\n",
      "[CV] END .........................................alpha=0.01; total time= 2.3min\n",
      "[CV] END ..........................................alpha=0.1; total time=   9.2s\n",
      "[CV] END ..........................................alpha=0.1; total time=   6.3s\n",
      "[CV] END ..........................................alpha=0.1; total time=  10.1s\n",
      "[CV] END ..........................................alpha=1.0; total time=   3.7s\n",
      "[CV] END ..........................................alpha=1.0; total time=   3.8s\n",
      "[CV] END ..........................................alpha=1.0; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvi/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.094e+03, tolerance: 4.920e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................................alpha=0.001; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvi/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.329e+03, tolerance: 4.919e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/yuvi/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.562e+03, tolerance: 4.918e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................................alpha=0.001; total time= 4.0min\n",
      "[CV] END ........................................alpha=0.001; total time= 4.0min\n",
      "\n",
      "--- Lasso GridSearchCV Results ---\n",
      "Tuning Time: 244.70s\n",
      "Best Alpha found: 0.01\n",
      "Best Cross-Validation Training RMSE (log): 0.6210\n",
      "Final Test RMSE (log) with best model: 0.6233\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train_to_tune = X1_train_scaled_poly\n",
    "y_train_to_tune = y1_train\n",
    "y_train_values = y_train_to_tune.values\n",
    "\n",
    "param_grid_lasso = {\n",
    "    'alpha': np.logspace(-3, 0, 4)  # [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "lasso_model = Lasso(random_state=42, max_iter=2000)\n",
    "\n",
    "print(f\"Starting GridSearchCV on Lasso Regression (alpha range: {param_grid_lasso['alpha']}) with {len(X_train_to_tune)} samples...\")\n",
    "start_time_grid_lasso = time.time()\n",
    "\n",
    "grid_search_lasso = GridSearchCV(\n",
    "    estimator=lasso_model,\n",
    "    param_grid=param_grid_lasso,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,       # 3-fold CV to save time on your large dataset\n",
    "    verbose=2,  # Higher verbose to see progress\n",
    "    n_jobs=4  # Use 4 CPU cores\n",
    ")\n",
    "\n",
    "grid_search_lasso.fit(X_train_to_tune, y_train_values)\n",
    "end_time_grid_lasso = time.time()\n",
    "tuning_time_lasso = end_time_grid_lasso - start_time_grid_lasso\n",
    "\n",
    "best_alpha_lasso = grid_search_lasso.best_params_['alpha']\n",
    "best_rmse_lasso_cv = np.sqrt(abs(grid_search_lasso.best_score_))\n",
    "\n",
    "best_lasso_model = grid_search_lasso.best_estimator_\n",
    "test_pred_lasso = best_lasso_model.predict(X1_test_scaled_poly)\n",
    "test_rmse_lasso = np.sqrt(mse(y1_test, test_pred_lasso))\n",
    "\n",
    "print(f\"\\n--- Lasso GridSearchCV Results ---\")\n",
    "print(f\"Tuning Time: {tuning_time_lasso:.2f}s\")\n",
    "print(f\"Best Alpha found: {best_alpha_lasso}\")\n",
    "print(f\"Best Cross-Validation Training RMSE (log): {best_rmse_lasso_cv:.4f}\")\n",
    "print(f\"Final Test RMSE (log) with best model: {test_rmse_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost (split ratio 0.2)...\n",
      "XGBoost (split ratio 0.2) finished. Test RMSE: 0.4566 | Training Time: 7.31s\n",
      "\n",
      "Training XGBoost (split ratio 0.3)...\n",
      "XGBoost (split ratio 0.3) finished. Test RMSE: 0.4556 | Training Time: 5.80s\n",
      "\n",
      "Training LightGBM (Split ratio 0.2)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12460\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166912, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score 6.467280\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM (Split ratio 0.2) finished. Test RMSE: 0.4555 | Training Time: 9.58s\n",
      "\n",
      "Training LightGBM (Split ratio 0.3)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12474\n",
      "[LightGBM] [Info] Number of data points in the train set: 1021048, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score 6.467477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM (Split ratio 0.3) finished. Test RMSE: 0.4543 | Training Time: 6.30s\n",
      "\n",
      "PCA complete.\n",
      "Training SVR ( RBF + PCA + Sampled 50000 for split ratio 0.2)...\n",
      "SVR ( RBF + PCA + Sampled 50000 for split ratio 0.2) finished. Test RMSE: 0.4856 | Training Time: 317.70s\n",
      "\n",
      "Training SVR ( RBF + PCA + Sampled 50000 for split ratio 0.3)...\n",
      "SVR ( RBF + PCA + Sampled 50000 for split ratio 0.3) finished. Test RMSE: 0.4860 | Training Time: 433.06s\n",
      "\n",
      "\n",
      "============================================================\n",
      "          FINAL MODEL COMPARISON (Test RMSE & Time)         \n",
      "============================================================\n",
      "|                                                      |   Test RMSE (log) |   Training Time (s) |   Rank |\n",
      "|:-----------------------------------------------------|------------------:|--------------------:|-------:|\n",
      "| LightGBM (Split ratio 0.3)                           |            0.4543 |              6.3042 | 1.0000 |\n",
      "| LightGBM (Split ratio 0.2)                           |            0.4555 |              9.5832 | 2.0000 |\n",
      "| XGBoost (split ratio 0.3)                            |            0.4556 |              5.7991 | 3.0000 |\n",
      "| XGBoost (split ratio 0.2)                            |            0.4566 |              7.3068 | 4.0000 |\n",
      "| SVR ( RBF + PCA + Sampled 50000 for split ratio 0.2) |            0.4856 |            317.7014 | 5.0000 |\n",
      "| SVR ( RBF + PCA + Sampled 50000 for split ratio 0.3) |            0.4860 |            433.0621 | 6.0000 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "def evaluate_model(model, X_train_data, y_train_data, X_test_data, y_test_data, model_name):\n",
    "    \"\"\"Fits model, records test RMSE, and prints training time.\"\"\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_data, y_train_data)\n",
    "    y_test_pred = model.predict(X_test_data)\n",
    "    rmse = np.sqrt(mse(y_test_data, y_test_pred))\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    final_results[model_name] = {'Test RMSE (log)': rmse, 'Training Time (s)': training_time}\n",
    "    print(f\"{model_name} finished. Test RMSE: {rmse:.4f} | Training Time: {training_time:.2f}s\\n\")\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, n_jobs=-1, random_state=42)\n",
    "evaluate_model(xgb_model, X1_train_scaled_poly, y1_train, X1_test_scaled_poly,y1_test ,\"XGBoost (split ratio 0.2)\")\n",
    "evaluate_model(xgb_model, X2_train_scaled_poly, y2_train, X2_test_scaled_poly,y2_test ,\"XGBoost (split ratio 0.3)\")\n",
    "\n",
    "lgbm_model = LGBMRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, n_jobs=-1, random_state=42)\n",
    "evaluate_model(lgbm_model, X1_train_scaled_poly, y1_train, X1_test_scaled_poly,y1_test, \"LightGBM (Split ratio 0.2)\")\n",
    "evaluate_model(lgbm_model, X2_train_scaled_poly, y2_train, X2_test_scaled_poly,y2_test, \"LightGBM (Split ratio 0.3)\")\n",
    "\n",
    "N_COMPONENTS = 15\n",
    "N_SAMPLE_FOR_SVR = 50000\n",
    "pca = PCA(n_components=N_COMPONENTS, random_state=42)\n",
    "X1_train_pca = pca.fit_transform(X1_train_scaled_poly)\n",
    "X1_test_pca = pca.transform(X1_test_scaled_poly)\n",
    "X2_train_pca = pca.fit_transform(X2_train_scaled_poly)\n",
    "X2_test_pca = pca.transform(X2_test_scaled_poly)\n",
    "print(\"PCA complete.\")\n",
    "\n",
    "n_available_rows_X1 = len(X1_train_pca)\n",
    "n_available_rows_X2 = len(X2_train_pca)\n",
    "actual_sample_size_X1 = min(N_SAMPLE_FOR_SVR, n_available_rows_X1)\n",
    "actual_sample_size_X2 = min(N_SAMPLE_FOR_SVR, n_available_rows_X2)\n",
    "sample_indices_X1 = np.random.choice(n_available_rows_X1, actual_sample_size_X1, replace=False)\n",
    "sample_indices_X2 = np.random.choice(n_available_rows_X2, actual_sample_size_X2, replace=False)\n",
    "X1_train_svr_pca = X1_train_pca[sample_indices_X1]\n",
    "y1_train_svr_pca = y1_train.iloc[sample_indices_X1]\n",
    "X2_train_svr_pca = X2_train_pca[sample_indices_X2]\n",
    "y2_train_svr_pca = y2_train.iloc[sample_indices_X2]\n",
    "\n",
    "svr_model_pca = SVR(kernel='rbf', C=1.0, epsilon=0.1) \n",
    "evaluate_model(\n",
    "    svr_model_pca,X1_train_svr_pca, y1_train_svr_pca, X1_test_pca,y1_test.values,f\"SVR ( RBF + PCA + Sampled {actual_sample_size_X1} for split ratio 0.2)\"\n",
    ")\n",
    "evaluate_model(\n",
    "    svr_model_pca, X2_train_svr_pca, y2_train_svr_pca, X2_test_pca,y2_test.values,f\"SVR ( RBF + PCA + Sampled {actual_sample_size_X2} for split ratio 0.3)\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"          FINAL MODEL COMPARISON (Test RMSE & Time)         \")\n",
    "print(\"=\"*60)\n",
    "df_results = pd.DataFrame.from_dict(final_results, orient='index')\n",
    "df_results = df_results.sort_values(by='Test RMSE (log)')\n",
    "df_results['Rank'] = np.arange(1, len(df_results) + 1)\n",
    "print(df_results.to_markdown(floatfmt=\".4f\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
